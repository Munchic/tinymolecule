{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.12 64-bit ('tinymolecule': conda)",
   "display_name": "Python 3.6.12 64-bit ('tinymolecule': conda)",
   "metadata": {
    "interpreter": {
     "hash": "e4c8154ec96457f858d943c3f44384e3378f5ac9cff4265db3fe00f22de39892"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")  # add top folder to path\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import moses\n",
    "import gentrl\n",
    "\n",
    "import tinymolecule as tiny"
   ]
  },
  {
   "source": [
    "## Initializing the encoder multilayer perceptron (MLP) and decoder MLP to form the variational autoencoder\n",
    "We note that the latent size for decoder is twice as small because we're drawing a sample from a distribution, whereas for the encoder, we get two values: mean and log variance. The MLPs are relatively small neural networks, by default there are two hidden layers, each with 100 neurons, and output layer (latent space) is 10 neurons. The decoder shares a similar structure but in reverse: the input from latent space is 5 neurons, with two hidden layers of 100 neurons."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tiny.LinearEncoder(latent_size=10)  # mu and sigma\n",
    "dec = tiny.LinearDecoder(latent_size=5)  # a single sample\n",
    "vae = tiny.TinyVAE(enc, dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = moses.get_dataset('train')\n",
    "train_encoded = gentrl.tokenizer.encode(train)[0].float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 1., 23., 23., 23., 25., 22., 13.,  9., 15., 10., 24., 10., 10., 10.,\n",
       "          3.,  7., 18., 21., 11., 10., 22., 13.,  6., 23., 22., 13.,  9., 15.,\n",
       "          9., 23., 15.,  7., 18., 21., 11., 10.,  3., 10., 24.,  2.,  2.,  2.,\n",
       "          2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.],\n",
       "        [ 1., 23., 23., 22., 23., 15., 22., 23., 15., 23., 22., 13.,  9., 15.,\n",
       "         23., 22.,  9., 10., 24., 10., 10., 10., 22.,  5., 15., 10., 10., 24.,\n",
       "         15., 18., 24., 10., 10., 18., 10., 24.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "          2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.],\n",
       "        [ 1., 23., 10., 24., 10., 22.,  5., 15., 10., 10., 10., 10., 24.,  6.,\n",
       "         10., 24., 18., 10., 10., 10., 10., 24., 23., 22., 13.,  9., 15.,  9.,\n",
       "         23., 23., 22.,  9., 15., 23.,  9.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "          2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.]])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "train_encoded[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "len(vae(train_encoded[0:3])[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecloader = tiny.dataset.molecloader(train_encoded)\n",
    "optimizer = optim.Adam(vae.parameters(), lr=1e-3)\n",
    "criterion = nn.BCELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1/5 started at 0.0000 s\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "all elements of input should be between 0 and 1",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-78b1425197fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtiny\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimple_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmolecloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Developer/Capstone/tinymolecule/tinymolecule/train.py\u001b[0m in \u001b[0;36msimple_train\u001b[0;34m(model, molecloader, criterion, optimizer, num_epochs, show_output)\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0mmolec_recon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmolec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                 \u001b[0mce_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmolec_recon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmolec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mce_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tinymolecule/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tinymolecule/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tinymolecule/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2483\u001b[0m     return torch._C._nn.binary_cross_entropy(\n\u001b[0;32m-> 2484\u001b[0;31m         input, target, weight, reduction_enum)\n\u001b[0m\u001b[1;32m   2485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: all elements of input should be between 0 and 1"
     ]
    }
   ],
   "source": [
    "train_loss = tiny.train.simple_train(vae, molecloader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "       grad_fn=<SigmoidBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "vae(train_encoded[0:3])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 1., 23., 23., 23., 25., 22., 13.,  9., 15., 10., 24., 10., 10., 10.,\n",
       "          3.,  7., 18., 21., 11., 10., 22., 13.,  6., 23., 22., 13.,  9., 15.,\n",
       "          9., 23., 15.,  7., 18., 21., 11., 10.,  3., 10., 24.,  2.,  2.,  2.,\n",
       "          2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.],\n",
       "        [ 1., 23., 23., 22., 23., 15., 22., 23., 15., 23., 22., 13.,  9., 15.,\n",
       "         23., 22.,  9., 10., 24., 10., 10., 10., 22.,  5., 15., 10., 10., 24.,\n",
       "         15., 18., 24., 10., 10., 18., 10., 24.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "          2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.],\n",
       "        [ 1., 23., 10., 24., 10., 22.,  5., 15., 10., 10., 10., 10., 24.,  6.,\n",
       "         10., 24., 18., 10., 10., 10., 10., 24., 23., 22., 13.,  9., 15.,  9.,\n",
       "         23., 23., 22.,  9., 15., 23.,  9.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "          2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.]])"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "train_encoded[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv(\"/Users/Munchic/Developer/Capstone/tinymolecule/data/ccr4_ic50_meta.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['', '', '']"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "gentrl.tokenizer.decode(vae(train_encoded[0:3])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.7311, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9526, 0.9991, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 0.9975, 1.0000, 1.0000, 1.0000, 0.9999,\n",
       "         1.0000, 0.9999, 1.0000, 1.0000, 0.9991, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         0.9526, 1.0000, 1.0000, 0.8808, 0.8808, 0.8808, 0.8808, 0.8808, 0.8808,\n",
       "         0.8808, 0.8808, 0.8808, 0.8808, 0.8808],\n",
       "        [0.7311, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9933, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         0.8808, 0.8808, 0.8808, 0.8808, 0.8808, 0.8808, 0.8808, 0.8808, 0.8808,\n",
       "         0.8808, 0.8808, 0.8808, 0.8808, 0.8808],\n",
       "        [0.7311, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9933, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 0.9975, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000,\n",
       "         0.9999, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 0.9999, 0.8808,\n",
       "         0.8808, 0.8808, 0.8808, 0.8808, 0.8808, 0.8808, 0.8808, 0.8808, 0.8808,\n",
       "         0.8808, 0.8808, 0.8808, 0.8808, 0.8808]])"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "torch.sigmoid(train_encoded[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 1., 23., 23., 23., 25., 22., 13.,  9., 15., 10., 24., 10., 10., 10.,\n",
       "          3.,  7., 18., 21., 11., 10., 22., 13.,  6., 23., 22., 13.,  9., 15.,\n",
       "          9., 23., 15.,  7., 18., 21., 11., 10.,  3., 10., 24.,  2.,  2.,  2.,\n",
       "          2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.],\n",
       "        [ 1., 23., 23., 22., 23., 15., 22., 23., 15., 23., 22., 13.,  9., 15.,\n",
       "         23., 22.,  9., 10., 24., 10., 10., 10., 22.,  5., 15., 10., 10., 24.,\n",
       "         15., 18., 24., 10., 10., 18., 10., 24.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "          2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.],\n",
       "        [ 1., 23., 10., 24., 10., 22.,  5., 15., 10., 10., 10., 10., 24.,  6.,\n",
       "         10., 24., 18., 10., 10., 10., 10., 24., 23., 22., 13.,  9., 15.,  9.,\n",
       "         23., 23., 22.,  9., 15., 23.,  9.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "          2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.]])"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "train_encoded[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = F.normalize(train_encoded[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.0100, 0.2304, 0.2304, 0.2304, 0.2504, 0.2204, 0.1302, 0.0901, 0.1502,\n",
       "         0.1002, 0.2404, 0.1002, 0.1002, 0.1002, 0.0300, 0.0701, 0.1803, 0.2103,\n",
       "         0.1102, 0.1002, 0.2204, 0.1302, 0.0601, 0.2304, 0.2204, 0.1302, 0.0901,\n",
       "         0.1502, 0.0901, 0.2304, 0.1502, 0.0701, 0.1803, 0.2103, 0.1102, 0.1002,\n",
       "         0.0300, 0.1002, 0.2404, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
       "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200],\n",
       "        [0.0095, 0.2195, 0.2195, 0.2099, 0.2195, 0.1431, 0.2099, 0.2195, 0.1431,\n",
       "         0.2195, 0.2099, 0.1240, 0.0859, 0.1431, 0.2195, 0.2099, 0.0859, 0.0954,\n",
       "         0.2290, 0.0954, 0.0954, 0.0954, 0.2099, 0.0477, 0.1431, 0.0954, 0.0954,\n",
       "         0.2290, 0.1431, 0.1717, 0.2290, 0.0954, 0.0954, 0.1717, 0.0954, 0.2290,\n",
       "         0.0191, 0.0191, 0.0191, 0.0191, 0.0191, 0.0191, 0.0191, 0.0191, 0.0191,\n",
       "         0.0191, 0.0191, 0.0191, 0.0191, 0.0191],\n",
       "        [0.0105, 0.2409, 0.1047, 0.2514, 0.1047, 0.2304, 0.0524, 0.1571, 0.1047,\n",
       "         0.1047, 0.1047, 0.1047, 0.2514, 0.0628, 0.1047, 0.2514, 0.1885, 0.1047,\n",
       "         0.1047, 0.1047, 0.1047, 0.2514, 0.2409, 0.2304, 0.1362, 0.0943, 0.1571,\n",
       "         0.0943, 0.2409, 0.2409, 0.2304, 0.0943, 0.1571, 0.2409, 0.0943, 0.0209,\n",
       "         0.0209, 0.0209, 0.0209, 0.0209, 0.0209, 0.0209, 0.0209, 0.0209, 0.0209,\n",
       "         0.0209, 0.0209, 0.0209, 0.0209, 0.0209]])"
      ]
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}